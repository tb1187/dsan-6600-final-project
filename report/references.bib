
@incollection{fleet_food-101_2014,
	address = {Cham},
	title = {Food-101 – {Mining} {Discriminative} {Components} with {Random} {Forests}},
	volume = {8694},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-319-10598-7 978-3-319-10599-4},
	url = {http://link.springer.com/10.1007/978-3-319-10599-4_29},
	abstract = {In this paper we address the problem of automatically recognizing pictured dishes. To this end, we introduce a novel method to mine discriminative parts using Random Forests (rf), which allows us to mine for parts simultaneously for all classes and to share knowledge among them. To improve eﬃciency of mining and classiﬁcation, we only consider patches that are aligned with image superpixels, which we call components. To measure the performance of our rf component mining for food recognition, we introduce a novel and challenging dataset of 101 food categories, with 101’000 images. With an average accuracy of 50.76\%, our model outperforms alternative classiﬁcation methods except for cnn, including svm classiﬁcation on Improved Fisher Vectors and existing discriminative part-mining algorithms by 11.88\% and 8.13\%, respectively. On the challenging mit-Indoor dataset, our method compares nicely to other s-o-a component-based classiﬁcation methods.},
	language = {en},
	urldate = {2025-11-18},
	booktitle = {Computer {Vision} – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	year = {2014},
	doi = {10.1007/978-3-319-10599-4_29},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {446--461},
	file = {PDF:C\:\\Users\\c18ty\\Zotero\\storage\\L8ARBVSD\\Bossard et al. - 2014 - Food-101 – Mining Discriminative Components with Random Forests.pdf:application/pdf},
}

@inproceedings{myers_im2calories_2015,
	address = {Santiago, Chile},
	title = {{Im2Calories}: {Towards} an {Automated} {Mobile} {Vision} {Food} {Diary}},
	isbn = {978-1-4673-8391-2},
	shorttitle = {{Im2Calories}},
	url = {http://ieeexplore.ieee.org/document/7410503/},
	doi = {10.1109/ICCV.2015.146},
	language = {en},
	urldate = {2025-11-18},
	booktitle = {2015 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Myers, Austin and Johnston, Nick and Rathod, Vivek and Korattikara, Anoop and Gorban, Alex and Silberman, Nathan and Guadarrama, Sergio and Papandreou, George and Huang, Jonathan and Murphy, Kevin},
	month = dec,
	year = {2015},
	pages = {1233--1241},
	file = {PDF:C\:\\Users\\c18ty\\Zotero\\storage\\DNV2QYPR\\Myers et al. - 2015 - Im2Calories Towards an Automated Mobile Vision Food Diary.pdf:application/pdf},
}

@inproceedings{thames_nutrition5k_2021,
	address = {Nashville, TN, USA},
	title = {Nutrition5k: {Towards} {Automatic} {Nutritional} {Understanding} of {Generic} {Food}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-6654-4509-2},
	shorttitle = {Nutrition5k},
	url = {https://ieeexplore.ieee.org/document/9577307/},
	doi = {10.1109/CVPR46437.2021.00879},
	abstract = {Understanding the nutritional content of food from visual data is a challenging computer vision problem, with the potential to have a positive and widespread impact on public health. Studies in this area are limited to existing datasets in the ﬁeld that lack sufﬁcient diversity or labels required for training models with nutritional understanding capability. We introduce Nutrition5k, a novel dataset of 5k diverse, real world food dishes with corresponding video streams, depth images, component weights, and high accuracy nutritional content annotation. We demonstrate the potential of this dataset by training a computer vision algorithm capable of predicting the caloric and macronutrient values of a complex, real world dish at an accuracy that outperforms professional nutritionists. Further we present a baseline for incorporating depth sensor data to improve nutrition predictions. We release Nutrition5k in the hope that it will accelerate innovation in the space of nutritional understanding. The dataset is available at https : / / github . com / google - research datasets/Nutrition5k.},
	language = {en},
	urldate = {2025-11-18},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Thames, Quin and Karpur, Arjun and Norris, Wade and Xia, Fangting and Panait, Liviu and Weyand, Tobias and Sim, Jack},
	month = jun,
	year = {2021},
	pages = {8899--8907},
	file = {PDF:C\:\\Users\\c18ty\\Zotero\\storage\\XF5YU87G\\Thames et al. - 2021 - Nutrition5k Towards Automatic Nutritional Understanding of Generic Food.pdf:application/pdf},
}

@misc{dong_mm-food-100k_2025,
	title = {{MM}-{Food}-{100K}: {A} 100,000-{Sample} {Multimodal} {Food} {Intelligence} {Dataset} with {Verifiable} {Provenance}},
	shorttitle = {{MM}-{Food}-{100K}},
	url = {http://arxiv.org/abs/2508.10429},
	doi = {10.48550/arXiv.2508.10429},
	abstract = {We present MM-Food-100K, a public 100,000-sample multimodal food intelligence dataset with verifiable provenance. It is a curated approximately 10\% open subset of an original 1.2 million, quality-accepted corpus of food images annotated for a wide range of information (such as dish name, region of creation). The corpus was collected over six weeks from over 87,000 contributors using the Codatta contribution model, which combines community sourcing with configurable AI-assisted quality checks; each submission is linked to a wallet address in a secure off-chain ledger for traceability, with a full on-chain protocol on the roadmap. We describe the schema, pipeline, and QA, and validate utility by fine-tuning large vision-language models (ChatGPT 5, ChatGPT OSS, Qwen-Max) on image-based nutrition prediction. Fine-tuning yields consistent gains over out-of-box baselines across standard metrics; we report results primarily on the MM-Food-100K subset. We release MM-Food-100K for publicly free access and retain approximately 90\% for potential commercial access with revenue sharing to contributors.},
	urldate = {2025-11-18},
	publisher = {arXiv},
	author = {Dong, Yi and Muraoka, Yusuke and Shi, Scott and Zhang, Yi},
	month = aug,
	year = {2025},
	note = {arXiv:2508.10429 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
	file = {Full Text PDF:C\:\\Users\\c18ty\\Zotero\\storage\\6EUBKHW4\\Dong et al. - 2025 - MM-Food-100K A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance.pdf:application/pdf;Snapshot:C\:\\Users\\c18ty\\Zotero\\storage\\N6KD2PCN\\2508.html:text/html},
}
